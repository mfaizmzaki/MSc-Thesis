# Copyright 2015 Abhinav Maurya

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

 
import fileinput
from sets import Set
import random
import scipy.special
import math
import dateparser, datetime
from scipy import integrate 
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import matplotlib
from pylab import *
import scipy.stats
from collections import Counter
from scipy.interpolate import spline
from scipy.stats import beta
from itertools import cycle
import pprint, pickle
import datetime

def convertDateToSeconds(dateString):
        
  dateFormatted = dateparser.parse(dateString, settings={'PREFER_DAY_OF_MONTH': 'last'}).date()
  dateSeconds = (dateFormatted - datetime.date(1970,1,1)).total_seconds()

  year = dateFormatted.year
  
  return dateSeconds,year

def VisualizeTopics(phi, words, num_topics, label):

	#to print top 50 words in each topic
	#argsort returns the indices of the elements
	topic_word = []

	for topic in range(len(phi)):
		topic_label = label.get(topic, 'autogenerated_topic')
		word_of_topic = np.argsort(phi[topic])[::-1][:50]
		word_in_text = [words[i] for i in word_of_topic]
		topic_word.append(word_in_text)
		print topic_label + ' ' + str(topic)
		print word_in_text

	return topic_word	

def VisualizeEvolution(topic, psi, label):
	
	xs = topic
	
	for i in range(len(xs)):
		plt.figure(i)
		
		xs[i].sort()
		print i
		print xs[i][0]
		print xs[i][len(xs[i])-1]

		denormalizedate = [(x * 341971200 + 1141084800) for x in xs[i]]
		xdates = [datetime.datetime.fromtimestamp(x) for x in denormalizedate]
		
		topic_label = label.get(i, 'autogenerated_topic ' + str(i))
		ys = [math.pow(1-x, psi[i][0]-1) * math.pow(x, psi[i][1]-1) / scipy.special.beta(psi[i][0],psi[i][1]) for x in xs[i]]
		plt.plot(xdates, ys, label=topic_label)
		plt.setp(plt.gca().xaxis.get_majorticklabels(),rotation=90)
		plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=12))
		plt.gca().xaxis.set_minor_locator(mdates.MonthLocator())
		plt.subplots_adjust(bottom=0.15)
		plt.xlabel('Year')
		plt.ylabel('Prob. Density')
		plt.legend(loc='best', frameon=False)
		savefig('/Users/mfaizmzaki/Desktop/result/Topic_evolution/noseed/Topic ' + str(i + 1))

def VisualizeByTime(psi, topic, timestamp, label):

	probTopicByTime = []

	norm_date = lambda x: 1.0*(x - 1141084800)/(1483056000 - 1141084800)

	dateseconds,year = convertDateToSeconds(timestamp)
	normDate = norm_date(dateseconds)

	if year == 2006:
		futureRange	= 26438400 #for 2006
	elif year == 2016:	
		futureRange	= 31449600 #for 2016
	else:
		futureRange = 31536000 #for all other years
		
	futureDate = dateseconds + futureRange
	normFutureDate = norm_date(futureDate)

	uniformTopic = 1.0/topic
	betapdf = lambda x: math.pow(1-x, psi[i][0]-1) * math.pow(x, psi[i][1]-1) / scipy.special.beta(psi[i][0],psi[i][1])

	x_labels = []
	
	for i in range(topic):
	  date_prob = integrate.quad(betapdf, normDate, normFutureDate)
	  topic_prob = date_prob[0] * uniformTopic
	  probTopicByTime.append(topic_prob)
	  topic_label = label.get(i, 'autogenerated_topic ' + str(i))
	  x_labels.append(topic_label)

	ys = probTopicByTime
	xs = [i+1 for i in range(topic)]

	year = dateparser.parse(timestamp).date().year
	plt.bar(xs, ys,label=year,align='center')
	plt.xticks(xs, x_labels, rotation=70, fontsize=20)
	plt.tick_params(labelsize=20)
	plt.margins(0.1)

	# Tweak spacing to prevent clipping of tick-labels
	plt.subplots_adjust(bottom=0.3)
	plt.xlabel('Topic',fontsize=20)
	plt.ylabel('Topic Probability',fontsize=20)
	plt.legend(loc='best', frameon=False)
	plt.show()


def get_cosine(numtopic, vec1topic, model1, model2):

	sim = []

	vec1 = text_to_vector(model1[vec1topic])

	for topic in model2:
		vec2 = text_to_vector(topic)

		intersection = set(vec1.keys()) & set(vec2.keys())
		numerator = sum([vec1[x] * vec2[x] for x in intersection])

		sum1 = sum([vec1[x]**2 for x in vec1.keys()])
		sum2 = sum([vec2[x]**2 for x in vec2.keys()])
		denominator = math.sqrt(sum1) * math.sqrt(sum2)

		if not denominator:
			cos_sim = 0.0
		else:
			cos_sim = float(numerator) / denominator

		sim.append(cos_sim)

	sim = np.array(sim)
	highest_sim = np.argmax(sim)
	hs = np.max(sim)
	print 'Highest sim ' + str(hs)
	return highest_sim

def text_to_vector(text):
    return Counter(text)



def main():
	resultspath = '/result/'
	tot_pickle_path = resultspath + '100iter_beta0_1.pickle'
	#compare_model = resultspath + 'noseed_100iter_beta0_1.pickle'

	tot_pickle = open(tot_pickle_path, 'rb')
	#tot_compare = open(compare_model, 'rb')
	
	par = pickle.load(tot_pickle)
	#comparepar = pickle.load(tot_compare)

	model1 = VisualizeTopics(par['n'], par['word_token'], par['T'], par['topic_label'])
	# model2 = VisualizeTopics(comparepar['n'], comparepar['word_token'], comparepar['T'], comparepar['topic_label'])

	# for i in range(par['T']):
	# 	sim = get_cosine(par['T'], i, model1, model2)
	# 	print 'Topic ' + str(i) + ' in model1 is most similar to Topic ' + str(sim) + ' in model2'
	VisualizeEvolution(par['topic_date'],par['psi'],par['topic_label'])
	VisualizeByTime(par['psi'], par['T'], '1/1/2016',par['topic_label'])

if __name__ == "__main__":
    main()
